{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NgHgHai/20130166_NguyenHoangHai_ML_2023/blob/main/Lab_5_20130166_NguyenHoangHai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to deal with **SVM** to classification tasks and compare its performance with other competitive algorithms. In general, **SVM** is one of the most popular and widely used supervised machine learning algorithms.\n",
        "\n",
        "*   **Deadline: 23:59, 17/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from numpy import average\n",
        "from sklearn import metrics\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "from prettytable import PrettyTable\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "For breast cancer dataset (https://tinyurl.com/3vme8hr3) which could be loaded from datasets in sklearn as follows:\n",
        "\n",
        "```\n",
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "```\n",
        "\n",
        "*   1.1.\tApply SVM algorithm to above dataset using linear kernel.\n",
        "*   1.2.\tCompare the obtained results with other competitive algorithms (Logistic Regression, Decision Tree, kNN) based on metrics: accuracy, precision, recall, f1 measures.\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "iris = datasets.load_iris()\n",
        "cancer = datasets.load_breast_cancer()\n",
        "mnist = datasets.load_digits()"
      ],
      "metadata": {
        "id": "q-UP5GQ80VRW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "\n",
        "x= cancer['data']\n",
        "y= cancer['target']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=5)\n",
        "# logis\n",
        "logis = LogisticRegression(random_state = 5,solver='lbfgs', max_iter=10000)\n",
        "logis.fit(x_train, y_train)\n",
        "y_pred_logis = logis.predict(x_test)\n",
        "\n",
        "accuracy_logis= round( accuracy_score(y_test, y_pred_logis),2)\n",
        "precision_logis = round( precision_score(y_test, y_pred_logis),2)\n",
        "recall_logis = round( recall_score(y_test, y_pred_logis),2)\n",
        "f1_logis = round( f1_score(y_test, y_pred_logis),2)\n",
        "\n",
        "# knn\n",
        "knn = KNeighborsClassifier(n_neighbors = 5)\n",
        "knn.fit(x_train, y_train)\n",
        "y_pred_knn = knn.predict(x_test)\n",
        "\n",
        "accuracy_knn = round( accuracy_score(y_test, y_pred_knn),2)\n",
        "precision_knn = round( precision_score(y_test, y_pred_knn),2)\n",
        "recall_knn =round(  recall_score(y_test, y_pred_knn),2)\n",
        "f1_knn = round( f1_score(y_test, y_pred_knn),2)\n",
        "\n",
        "# dt\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(x_train, y_train)\n",
        "y_pred_dt = dt.predict(x_test)\n",
        "\n",
        "accuracy_dt =round(  accuracy_score(y_test, y_pred_dt),2)\n",
        "precision_dt =round(  precision_score(y_test, y_pred_dt),2)\n",
        "recall_dt =round(  recall_score(y_test, y_pred_dt),2)\n",
        "f1_dt =round(  f1_score(y_test, y_pred_dt),2)\n",
        "\n",
        "# svm\n",
        "svm_ = svm.SVC(kernel='linear')\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_svm = svm_.predict(x_test)\n",
        "\n",
        "accuracy_svm =round(  accuracy_score(y_test, y_pred_svm),2)\n",
        "precision_svm =round(  precision_score(y_test, y_pred_svm),2)\n",
        "recall_svm =round(  recall_score(y_test, y_pred_svm),2)\n",
        "f1_svm =round(  f1_score(y_test, y_pred_svm),2)\n",
        "\n",
        "#display\n",
        "t= PrettyTable(['algorithms','acc','pre','recall','f1'])\n",
        "t.add_row(['logis',accuracy_logis,precision_logis,recall_logis,f1_logis])\n",
        "t.add_row(['knn',accuracy_knn,precision_knn,recall_knn,f1_knn])\n",
        "t.add_row(['tree',accuracy_dt,precision_dt,recall_dt,f1_dt])\n",
        "t.add_row(['svm(Linear)',accuracy_svm,precision_svm,recall_svm,f1_svm])\n",
        "print(t)\n",
        "# ==================================================================\n",
        "# task 2.2\n",
        "# linear\n",
        "svm_ = svm.SVC(kernel='linear')\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_linear = svm_.predict(x_test)\n",
        "\n",
        "accuracy_linear =round(  accuracy_score(y_test, y_pred_linear),2)\n",
        "precision_linear =round(  precision_score(y_test, y_pred_linear,average ='macro'),2)\n",
        "recall_linear =round(  recall_score(y_test, y_pred_linear,average ='macro'),2)\n",
        "f1_linear =round(  f1_score(y_test, y_pred_linear,average ='macro'),2)\n",
        "# poly\n",
        "svm_ = svm.SVC(kernel='poly',degree=4)\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_poly = svm_.predict(x_test)\n",
        "\n",
        "accuracy_poly =round(  accuracy_score(y_test, y_pred_poly),2)\n",
        "precision_poly =round(  precision_score(y_test, y_pred_poly,average ='macro'),2)\n",
        "recall_poly =round(  recall_score(y_test, y_pred_poly,average ='macro'),2)\n",
        "f1_poly =round(  f1_score(y_test, y_pred_poly,average ='macro'),2)\n",
        "# sigmoid\n",
        "svm_ = svm.SVC(kernel='sigmoid')\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_sigmoid = svm_.predict(x_test)\n",
        "\n",
        "accuracy_sigmoid =round(  accuracy_score(y_test, y_pred_sigmoid),2)\n",
        "precision_sigmoid =round(  precision_score(y_test, y_pred_sigmoid,average ='macro'),2)\n",
        "recall_sigmoid =round(  recall_score(y_test, y_pred_sigmoid,average ='macro'),2)\n",
        "f1_sigmoid =round(  f1_score(y_test, y_pred_sigmoid,average ='macro'),2)\n",
        "\n",
        "#  Radial Basis\n",
        "svm_ = svm.SVC(kernel='rbf')\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_rbf = svm_.predict(x_test)\n",
        "\n",
        "accuracy_rbf =round(  accuracy_score(y_test, y_pred_rbf),2)\n",
        "precision_rbf =round(  precision_score(y_test, y_pred_rbf,average ='macro'),2)\n",
        "recall_rbf =round(  recall_score(y_test, y_pred_rbf,average ='macro'),2)\n",
        "f1_rbf =round(  f1_score(y_test, y_pred_rbf,average ='macro'),2)\n",
        "\n",
        "#display\n",
        "t= PrettyTable(['algorithms (svm)','acc','pre','recall','f1'])\n",
        "t.add_row(['linear',accuracy_linear,precision_linear,recall_linear,f1_linear])\n",
        "t.add_row(['poly',accuracy_poly,precision_poly,recall_poly,f1_poly])\n",
        "t.add_row(['sigmoid',accuracy_sigmoid,precision_sigmoid,recall_sigmoid,f1_sigmoid])\n",
        "t.add_row(['rbf',accuracy_rbf,precision_rbf,recall_rbf,f1_rbf])\n",
        "print(t)\n",
        "\n"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaece317-dd1f-4ffa-ac86-8e7bee0319ab"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------+------+--------+------+\n",
            "|  algorithms | acc  | pre  | recall |  f1  |\n",
            "+-------------+------+------+--------+------+\n",
            "|    logis    | 0.98 | 0.98 |  0.99  | 0.99 |\n",
            "|     knn     | 0.95 | 0.94 |  0.98  | 0.96 |\n",
            "|     tree    | 0.94 | 0.95 |  0.95  | 0.95 |\n",
            "| svm(Linear) | 0.98 | 0.99 |  0.98  | 0.99 |\n",
            "+-------------+------+------+--------+------+\n",
            "+------------------+------+------+--------+------+\n",
            "| algorithms (svm) | acc  | pre  | recall |  f1  |\n",
            "+------------------+------+------+--------+------+\n",
            "|      linear      | 0.98 | 0.98 |  0.98  | 0.98 |\n",
            "|       poly       | 0.95 | 0.97 |  0.93  | 0.95 |\n",
            "|     sigmoid      | 0.48 | 0.33 |  0.38  | 0.35 |\n",
            "|       rbf        | 0.96 | 0.97 |  0.95  | 0.96 |\n",
            "+------------------+------+------+--------+------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "\n",
        "*   1.1.\tPerform SVM algorithm to **Iris dataset** using **linear kernel**.\n",
        "*   1.2.\tCompare the obtained results in 1.1 with SVM using other kernels (**Polynomial Kernel, Gaussian Kernel, Sigmoid Kernel, Radial Basis Function Kernel**). Some metrics could be used: accuracy, precision, recall, f1 measures\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S43IoUT-0OQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "\n",
        "x= iris['data']\n",
        "y= iris['target']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=5)\n",
        "# linear\n",
        "svm_ = svm.SVC(kernel='linear')\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_linear = svm_.predict(x_test)\n",
        "\n",
        "accuracy_linear =round(  accuracy_score(y_test, y_pred_linear),2)\n",
        "precision_linear =round(  precision_score(y_test, y_pred_linear,average ='macro'),2)\n",
        "recall_linear =round(  recall_score(y_test, y_pred_linear,average ='macro'),2)\n",
        "f1_linear =round(  f1_score(y_test, y_pred_linear,average ='macro'),2)\n",
        "# poly\n",
        "svm_ = svm.SVC(kernel='poly',degree=4)\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_poly = svm_.predict(x_test)\n",
        "\n",
        "accuracy_poly =round(  accuracy_score(y_test, y_pred_poly),2)\n",
        "precision_poly =round(  precision_score(y_test, y_pred_poly,average ='macro'),2)\n",
        "recall_poly =round(  recall_score(y_test, y_pred_poly,average ='macro'),2)\n",
        "f1_poly =round(  f1_score(y_test, y_pred_poly,average ='macro'),2)\n",
        "# sigmoid\n",
        "svm_ = svm.SVC(kernel='sigmoid')\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_sigmoid = svm_.predict(x_test)\n",
        "\n",
        "accuracy_sigmoid =round(  accuracy_score(y_test, y_pred_sigmoid),2)\n",
        "precision_sigmoid =round(  precision_score(y_test, y_pred_sigmoid,average ='macro'),2)\n",
        "recall_sigmoid =round(  recall_score(y_test, y_pred_sigmoid,average ='macro'),2)\n",
        "f1_sigmoid =round(  f1_score(y_test, y_pred_sigmoid,average ='macro'),2)\n",
        "\n",
        "#  Radial Basis\n",
        "svm_ = svm.SVC(kernel='rbf')\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_rbf = svm_.predict(x_test)\n",
        "\n",
        "accuracy_rbf =round(  accuracy_score(y_test, y_pred_rbf),2)\n",
        "precision_rbf =round(  precision_score(y_test, y_pred_rbf,average ='macro'),2)\n",
        "recall_rbf =round(  recall_score(y_test, y_pred_rbf,average ='macro'),2)\n",
        "f1_rbf =round(  f1_score(y_test, y_pred_rbf,average ='macro'),2)\n",
        "\n",
        "#display\n",
        "t= PrettyTable(['algorithms','acc','pre','recall','f1'])\n",
        "t.add_row(['linear',accuracy_linear,precision_linear,recall_linear,f1_linear])\n",
        "t.add_row(['poly',accuracy_poly,precision_poly,recall_poly,f1_poly])\n",
        "t.add_row(['sigmoid',accuracy_sigmoid,precision_sigmoid,recall_sigmoid,f1_sigmoid])\n",
        "t.add_row(['rbf',accuracy_rbf,precision_rbf,recall_rbf,f1_rbf])\n",
        "print(t)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_xhPpF5b033h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c453f1f7-f960-4d84-bef6-cec89e5471a2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------+------+--------+------+\n",
            "| algorithms | acc  | pre  | recall |  f1  |\n",
            "+------------+------+------+--------+------+\n",
            "|   linear   | 0.96 | 0.96 |  0.96  | 0.96 |\n",
            "|    poly    | 0.96 | 0.96 |  0.96  | 0.96 |\n",
            "|  sigmoid   | 0.31 | 0.1  |  0.33  | 0.16 |\n",
            "|    rbf     | 0.98 | 0.98 |  0.98  | 0.98 |\n",
            "+------------+------+------+--------+------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "Compare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression) and SVM (using different kernels) with mnist dataset based on accuracy, precision, recall, f1 measures.\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x= mnist['data']\n",
        "y= mnist['target']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=5)\n",
        "# logis\n",
        "logis = LogisticRegression(random_state = 5,solver='lbfgs', max_iter=10000)\n",
        "logis.fit(x_train, y_train)\n",
        "y_pred_logis = logis.predict(x_test)\n",
        "\n",
        "accuracy_logis= round( accuracy_score(y_test, y_pred_logis),2)\n",
        "precision_logis = round( precision_score(y_test, y_pred_logis,average ='macro'),2)\n",
        "recall_logis = round( recall_score(y_test, y_pred_logis,average ='macro'),2)\n",
        "f1_logis = round( f1_score(y_test, y_pred_logis,average ='macro'),2)\n",
        "\n",
        "# knn\n",
        "knn = KNeighborsClassifier(n_neighbors = 5)\n",
        "knn.fit(x_train, y_train)\n",
        "y_pred_knn = knn.predict(x_test)\n",
        "\n",
        "accuracy_knn = round( accuracy_score(y_test, y_pred_knn),2)\n",
        "precision_knn = round( precision_score(y_test, y_pred_knn,average ='macro'),2)\n",
        "recall_knn =round(  recall_score(y_test, y_pred_knn,average ='macro'),2)\n",
        "f1_knn = round( f1_score(y_test, y_pred_knn,average ='macro'),2)\n",
        "\n",
        "# dt\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(x_train, y_train)\n",
        "y_pred_dt = dt.predict(x_test)\n",
        "\n",
        "accuracy_dt =round(  accuracy_score(y_test, y_pred_dt),2)\n",
        "precision_dt =round(  precision_score(y_test, y_pred_dt,average ='macro'),2)\n",
        "recall_dt =round(  recall_score(y_test, y_pred_dt,average ='macro'),2)\n",
        "f1_dt =round(  f1_score(y_test, y_pred_dt,average ='macro'),2)\n",
        "\n",
        "# svm\n",
        "svm_ = svm.SVC(kernel='linear')\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_svm = svm_.predict(x_test)\n",
        "\n",
        "accuracy_svm =round(  accuracy_score(y_test, y_pred_svm),2)\n",
        "precision_svm =round(  precision_score(y_test, y_pred_svm,average ='macro'),2)\n",
        "recall_svm =round(  recall_score(y_test, y_pred_svm,average ='macro'),2)\n",
        "f1_svm =round(  f1_score(y_test, y_pred_svm,average ='macro'),2)\n",
        "\n",
        "#display\n",
        "t= PrettyTable(['algorithms','acc','pre','recall','f1'])\n",
        "t.add_row(['logis',accuracy_logis,precision_logis,recall_logis,f1_logis])\n",
        "t.add_row(['knn',accuracy_knn,precision_knn,recall_knn,f1_knn])\n",
        "t.add_row(['tree',accuracy_dt,precision_dt,recall_dt,f1_dt])\n",
        "t.add_row(['svm(Linear)',accuracy_svm,precision_svm,recall_svm,f1_svm])\n",
        "print(t)\n",
        "# ==================================================================\n",
        "# task 2.2\n",
        "# linear\n",
        "svm_ = svm.SVC(kernel='linear')\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_linear = svm_.predict(x_test)\n",
        "\n",
        "accuracy_linear =round(  accuracy_score(y_test, y_pred_linear),2)\n",
        "precision_linear =round(  precision_score(y_test, y_pred_linear,average ='macro'),2)\n",
        "recall_linear =round(  recall_score(y_test, y_pred_linear,average ='macro'),2)\n",
        "f1_linear =round(  f1_score(y_test, y_pred_linear,average ='macro'),2)\n",
        "# poly\n",
        "svm_ = svm.SVC(kernel='poly',degree=4)\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_poly = svm_.predict(x_test)\n",
        "\n",
        "accuracy_poly =round(  accuracy_score(y_test, y_pred_poly),2)\n",
        "precision_poly =round(  precision_score(y_test, y_pred_poly,average ='macro'),2)\n",
        "recall_poly =round(  recall_score(y_test, y_pred_poly,average ='macro'),2)\n",
        "f1_poly =round(  f1_score(y_test, y_pred_poly,average ='macro'),2)\n",
        "# sigmoid\n",
        "svm_ = svm.SVC(kernel='sigmoid')\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_sigmoid = svm_.predict(x_test)\n",
        "\n",
        "accuracy_sigmoid =round(  accuracy_score(y_test, y_pred_sigmoid),2)\n",
        "precision_sigmoid =round(  precision_score(y_test, y_pred_sigmoid,average ='macro'),2)\n",
        "recall_sigmoid =round(  recall_score(y_test, y_pred_sigmoid,average ='macro'),2)\n",
        "f1_sigmoid =round(  f1_score(y_test, y_pred_sigmoid,average ='macro'),2)\n",
        "\n",
        "#  Radial Basis\n",
        "svm_ = svm.SVC(kernel='rbf')\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_rbf = svm_.predict(x_test)\n",
        "\n",
        "accuracy_rbf =round(  accuracy_score(y_test, y_pred_rbf),2)\n",
        "precision_rbf =round(  precision_score(y_test, y_pred_rbf,average ='macro'),2)\n",
        "recall_rbf =round(  recall_score(y_test, y_pred_rbf,average ='macro'),2)\n",
        "f1_rbf =round(  f1_score(y_test, y_pred_rbf,average ='macro'),2)\n",
        "\n",
        "#display\n",
        "t= PrettyTable(['algorithms (svm)','acc','pre','recall','f1'])\n",
        "t.add_row(['linear',accuracy_linear,precision_linear,recall_linear,f1_linear])\n",
        "t.add_row(['poly',accuracy_poly,precision_poly,recall_poly,f1_poly])\n",
        "t.add_row(['sigmoid',accuracy_sigmoid,precision_sigmoid,recall_sigmoid,f1_sigmoid])\n",
        "t.add_row(['rbf',accuracy_rbf,precision_rbf,recall_rbf,f1_rbf])\n",
        "print(t)\n",
        "# thong ke cu the tung class\n",
        "print(metrics.classification_report(y_test,y_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NN_TRGF1sFP",
        "outputId": "f2b92542-b5cc-4d5c-b2bd-6e42ca400e58"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------+------+--------+------+\n",
            "|  algorithms | acc  | pre  | recall |  f1  |\n",
            "+-------------+------+------+--------+------+\n",
            "|    logis    | 0.96 | 0.96 |  0.96  | 0.96 |\n",
            "|     knn     | 0.99 | 0.99 |  0.98  | 0.98 |\n",
            "|     tree    | 0.86 | 0.86 |  0.86  | 0.86 |\n",
            "| svm(Linear) | 0.98 | 0.98 |  0.98  | 0.98 |\n",
            "+-------------+------+------+--------+------+\n",
            "+------------------+------+------+--------+------+\n",
            "| algorithms (svm) | acc  | pre  | recall |  f1  |\n",
            "+------------------+------+------+--------+------+\n",
            "|      linear      | 0.98 | 0.98 |  0.98  | 0.98 |\n",
            "|       poly       | 0.99 | 0.99 |  0.99  | 0.99 |\n",
            "|     sigmoid      | 0.91 | 0.91 |  0.91  | 0.91 |\n",
            "|       rbf        | 0.99 | 0.99 |  0.99  | 0.99 |\n",
            "+------------------+------+------+--------+------+\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        58\n",
            "           1       0.96      1.00      0.98        52\n",
            "           2       0.98      1.00      0.99        58\n",
            "           3       1.00      0.95      0.97        59\n",
            "           4       1.00      0.98      0.99        43\n",
            "           5       0.97      0.98      0.98        64\n",
            "           6       1.00      1.00      1.00        47\n",
            "           7       1.00      0.98      0.99        59\n",
            "           8       1.00      0.96      0.98        50\n",
            "           9       0.92      0.98      0.95        50\n",
            "\n",
            "    accuracy                           0.98       540\n",
            "   macro avg       0.98      0.98      0.98       540\n",
            "weighted avg       0.98      0.98      0.98       540\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "Compare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression) and SVM (using different kernels) with **credit card dataset** based on accuracy, precision, recall, f1 measures.\n",
        "\n",
        "*   Give some comments on the obtained results\n",
        "*   Identify issues with dataset, and propose the solutions to these issues\n",
        "\n"
      ],
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "# len UCI lay datasheet, doc du lieu tu file, creditcard.csv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/ML_2023/Lab5/'\n"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd1fcf0e-2e6e-4d43-c0d4-c7098bb3b9e9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/ML_2023/Lab5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "creditcard = pd.read_csv(\"creditcard.csv\")\n",
        "creditcard = creditcard.iloc[0:140000,:]\n",
        "# chuan hoa\n",
        "x= creditcard.drop(columns=[\"Time\",\"Class\"])\n",
        "# x= creditcard.iloc[:,1:30].values\n",
        "y= creditcard['Class']\n",
        "# x= x.iloc[0:140000,:]\n",
        "print(y)\n",
        "# creditcard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHbQxOZs6tjH",
        "outputId": "c009b9a0-5853-494d-88d4-1eb62551b468"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         0\n",
            "1         0\n",
            "2         0\n",
            "3         0\n",
            "4         0\n",
            "         ..\n",
            "139995    0\n",
            "139996    0\n",
            "139997    0\n",
            "139998    0\n",
            "139999    0\n",
            "Name: Class, Length: 140000, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=5)\n",
        "# logis\n",
        "logis = LogisticRegression(random_state = 5,solver='lbfgs', max_iter=10000)\n",
        "logis.fit(x_train, y_train)\n",
        "y_pred_logis = logis.predict(x_test)\n",
        "\n",
        "accuracy_logis= round( accuracy_score(y_test, y_pred_logis),2)\n",
        "precision_logis = round( precision_score(y_test, y_pred_logis,average ='macro'),2)\n",
        "recall_logis = round( recall_score(y_test, y_pred_logis,average ='macro'),2)\n",
        "f1_logis = round( f1_score(y_test, y_pred_logis,average ='macro'),2)\n",
        "\n",
        "# knn\n",
        "knn = KNeighborsClassifier(n_neighbors = 5)\n",
        "knn.fit(x_train, y_train)\n",
        "y_pred_knn = knn.predict(x_test)\n",
        "\n",
        "accuracy_knn = round( accuracy_score(y_test, y_pred_knn),2)\n",
        "precision_knn = round( precision_score(y_test, y_pred_knn,average ='macro'),2)\n",
        "recall_knn =round(  recall_score(y_test, y_pred_knn,average ='macro'),2)\n",
        "f1_knn = round( f1_score(y_test, y_pred_knn,average ='macro'),2)\n",
        "\n",
        "# dt\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(x_train, y_train)\n",
        "y_pred_dt = dt.predict(x_test)\n",
        "\n",
        "accuracy_dt =round(  accuracy_score(y_test, y_pred_dt),2)\n",
        "precision_dt =round(  precision_score(y_test, y_pred_dt,average ='macro'),2)\n",
        "recall_dt =round(  recall_score(y_test, y_pred_dt,average ='macro'),2)\n",
        "f1_dt =round(  f1_score(y_test, y_pred_dt,average ='macro'),2)\n",
        "\n",
        "# svm\n",
        "svm_ = svm.SVC(kernel='linear')\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_svm = svm_.predict(x_test)\n",
        "\n",
        "accuracy_svm =round(  accuracy_score(y_test, y_pred_svm),2)\n",
        "precision_svm =round(  precision_score(y_test, y_pred_svm,average ='macro'),2)\n",
        "recall_svm =round(  recall_score(y_test, y_pred_svm,average ='macro'),2)\n",
        "f1_svm =round(  f1_score(y_test, y_pred_svm,average ='macro'),2)\n",
        "\n",
        "#display\n",
        "t= PrettyTable(['algorithms','acc','pre','recall','f1'])\n",
        "t.add_row(['logis',accuracy_logis,precision_logis,recall_logis,f1_logis])\n",
        "t.add_row(['knn',accuracy_knn,precision_knn,recall_knn,f1_knn])\n",
        "t.add_row(['tree',accuracy_dt,precision_dt,recall_dt,f1_dt])\n",
        "t.add_row(['svm(Linear)',accuracy_svm,precision_svm,recall_svm,f1_svm])\n",
        "print(t)\n",
        "# ==================================================================\n",
        "# task 2.2\n",
        "# linear\n",
        "svm_ = svm.SVC(kernel='linear')\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_linear = svm_.predict(x_test)\n",
        "\n",
        "accuracy_linear =round(  accuracy_score(y_test, y_pred_linear),2)\n",
        "precision_linear =round(  precision_score(y_test, y_pred_linear,average ='macro'),2)\n",
        "recall_linear =round(  recall_score(y_test, y_pred_linear,average ='macro'),2)\n",
        "f1_linear =round(  f1_score(y_test, y_pred_linear,average ='macro'),2)\n",
        "# poly\n",
        "svm_ = svm.SVC(kernel='poly',degree=4)\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_poly = svm_.predict(x_test)\n",
        "\n",
        "accuracy_poly =round(  accuracy_score(y_test, y_pred_poly),2)\n",
        "precision_poly =round(  precision_score(y_test, y_pred_poly,average ='macro'),2)\n",
        "recall_poly =round(  recall_score(y_test, y_pred_poly,average ='macro'),2)\n",
        "f1_poly =round(  f1_score(y_test, y_pred_poly,average ='macro'),2)\n",
        "# sigmoid\n",
        "svm_ = svm.SVC(kernel='sigmoid')\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_sigmoid = svm_.predict(x_test)\n",
        "\n",
        "accuracy_sigmoid =round(  accuracy_score(y_test, y_pred_sigmoid),2)\n",
        "precision_sigmoid =round(  precision_score(y_test, y_pred_sigmoid,average ='macro'),2)\n",
        "recall_sigmoid =round(  recall_score(y_test, y_pred_sigmoid,average ='macro'),2)\n",
        "f1_sigmoid =round(  f1_score(y_test, y_pred_sigmoid,average ='macro'),2)\n",
        "\n",
        "#  Radial Basis\n",
        "svm_ = svm.SVC(kernel='rbf')\n",
        "svm_.fit(x_train, y_train)\n",
        "y_pred_rbf = svm_.predict(x_test)\n",
        "\n",
        "accuracy_rbf =round(  accuracy_score(y_test, y_pred_rbf),2)\n",
        "precision_rbf =round(  precision_score(y_test, y_pred_rbf,average ='macro'),2)\n",
        "recall_rbf =round(  recall_score(y_test, y_pred_rbf,average ='macro'),2)\n",
        "f1_rbf =round(  f1_score(y_test, y_pred_rbf,average ='macro'),2)\n",
        "\n",
        "#display\n",
        "t= PrettyTable(['algorithms (svm)','acc','pre','recall','f1'])\n",
        "t.add_row(['linear',accuracy_linear,precision_linear,recall_linear,f1_linear])\n",
        "t.add_row(['poly',accuracy_poly,precision_poly,recall_poly,f1_poly])\n",
        "t.add_row(['sigmoid',accuracy_sigmoid,precision_sigmoid,recall_sigmoid,f1_sigmoid])\n",
        "t.add_row(['rbf',accuracy_rbf,precision_rbf,recall_rbf,f1_rbf])\n",
        "print(t)\n",
        "# thong ke cu the tung class\n",
        "print(metrics.classification_report(y_test,y_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "309LpZMo6CIQ",
        "outputId": "e7caaee8-e842-4cae-d548-7d1a2aa325eb"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-81bfd8228b2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0my_pred_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0maccuracy_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_knn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# In that case, we do not need the distances to perform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;31m# the weighting so we do not compute them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mneigh_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    822\u001b[0m         )\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_pairwise_distances_reductions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             results = ArgKmin.compute(\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \"\"\"\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             return ArgKmin64.compute(\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\u001b[0m in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_original_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}